"""
Christopher Ondrusz
GitHub: acse_cro23
"""
from .utils import loss_function, surrogate_target, compute_alpha_sigma, noise_schedule # noqa
import torch.nn as nn
import torch
from torch.optim import Adam


class DiffusionModel(nn.Module):
    """
    A diffusion model that uses a base neural network model (e.g., UNet)
    to perform denoising and sampling tasks. The model can be trained using
    a specified noise schedule.

    Parameters:
    -----------
    model : nn.Module
        The base neural network model architecture (e.g., UNet).
    lambda_start : float, optional, default=1.0
        The starting value for the lambda schedule.
    lambda_end : float, optional, default=0.0
        The ending value for the lambda schedule.
    device : str, optional, default='cuda' if torch.cuda.is_available() else 'cpu' # noqa
        The device to run the model on ('cuda' or 'cpu').

    Returns:
    --------
    None
    """
    def __init__(self,
                 model,
                 lambda_start=1.0,
                 lambda_end=0.,
                 device='cuda' if torch.cuda.is_available() else 'cpu'):
        super(DiffusionModel, self).__init__()
        self.model = model.to(device)
        self.device = device
        self.lambda_t = torch.linspace(1, 0, 50, requires_grad=True)
        self.alpha_t, self.sigma_t = compute_alpha_sigma(self.lambda_t)

    def train_model(self, dataloader, train_steps=1000, epochs=50):
        """
        Trains the diffusion model using the provided dataloader.

        Parameters:
        -----------
        dataloader : torch.utils.data.DataLoader
            The dataloader providing batches of data for training.
        train_steps : int, optional, default=1000
            The number of diffusion steps used in training.
        epochs : int, optional, default=50
            The number of epochs for which to train the model.

        Returns:
        --------
        None
        """
        lambda_tau = noise_schedule(1000, schedule_type="cosine")
        alpha_tau, sigma_tau = compute_alpha_sigma(lambda_tau)
        optimizer = Adam(self.model.parameters(), lr=1e-3)
        self.model.train()
        for epoch in range(epochs):
            for x_t, x_t_plus in dataloader:
                t_int = torch.randint(0, train_steps,
                                      (x_t.shape[0],),
                                      device=self.device)
                t = t_int.float().requires_grad_(True) / train_steps
                optimizer.zero_grad()
                v_tau = surrogate_target(x_t_plus, t_int,
                                         alpha_tau, sigma_tau)
                v_hat = self.model(x_t)
                loss = loss_function(v_tau, v_hat, self.lambda_t, t)
                loss.backward(retain_graph=True)
                optimizer.step()
            print(f"Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}")
        torch.save(self.model.state_dict(), f"./UNetDiff_epoch_{epochs}.pt")

    def diffusion_sampler(self, x_t, num_steps=50):
        """
        Generates samples from the diffusion model.

        Parameters:
        -----------
        x_t : torch.Tensor
            The input tensor representing the noisy data to be denoised.
        num_steps : int, optional, default=50
            The number of sampling steps to perform.

        Returns:
        --------
        torch.Tensor
            The denoised output tensor generated by the model.
        """
        if num_steps != 50:
            lambda_tau = torch.linspace(1, 0, num_steps, requires_grad=True,
                                        device=self.device)
            alpha_t, sigma_t = compute_alpha_sigma(lambda_tau)
        else:
            lambda_tau = self.lambda_t,
            alpha_t, sigma_t = self.alpha_t, self.sigma_t
        z_t = torch.randn_like(x_t).to(self.device)*255
        x_t = x_t.to(self.device)
        for t in reversed(range(num_steps)):
            tau = torch.tensor([t], dtype=torch.float32).to(self.device)
            z_tau = z_t.clone()
            v_hat = self.model(x_t)
            z_t = alpha_t[tau.long()]*z_tau-sigma_t[tau.long()]*v_hat
        return z_t

    def save_model(self, path):
        """
        Saves the model's state dictionary to a specified path.

        Parameters:
        -----------
        path : str
            The file path where the model's state dictionary will be saved.

        Returns:
        --------
        None
        """
        torch.save(self.model.state_dict(), path)
        print(f"Model saved to {path}")

    def load_model(self, path):
        """
        Loads the model's state dictionary from a specified path.

        Parameters:
        -----------
        path : str
            The file path from which to load the model's state dictionary.

        Returns:
        --------
        None
        """
        self.model.load_state_dict(torch.load(path, map_location=self.device))
        self.model.to(self.device)
        print(f"Model loaded from {path}")
