%% Generated by Sphinx.
\def\sphinxdocclass{report}
\documentclass[a4paper,10pt,english]{sphinxmanual}
\ifdefined\pdfpxdimen
   \let\sphinxpxdimen\pdfpxdimen\else\newdimen\sphinxpxdimen
\fi \sphinxpxdimen=.75bp\relax
\ifdefined\pdfimageresolution
    \pdfimageresolution= \numexpr \dimexpr1in\relax/\sphinxpxdimen\relax
\fi
%% let collapsible pdf bookmarks panel have high depth per default
\PassOptionsToPackage{bookmarksdepth=5}{hyperref}

\PassOptionsToPackage{booktabs}{sphinx}
\PassOptionsToPackage{colorrows}{sphinx}

\PassOptionsToPackage{warn}{textcomp}
\usepackage[utf8]{inputenc}
\ifdefined\DeclareUnicodeCharacter
% support both utf8 and utf8x syntaxes
  \ifdefined\DeclareUnicodeCharacterAsOptional
    \def\sphinxDUC#1{\DeclareUnicodeCharacter{"#1}}
  \else
    \let\sphinxDUC\DeclareUnicodeCharacter
  \fi
  \sphinxDUC{00A0}{\nobreakspace}
  \sphinxDUC{2500}{\sphinxunichar{2500}}
  \sphinxDUC{2502}{\sphinxunichar{2502}}
  \sphinxDUC{2514}{\sphinxunichar{2514}}
  \sphinxDUC{251C}{\sphinxunichar{251C}}
  \sphinxDUC{2572}{\textbackslash}
\fi
\usepackage{cmap}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amssymb,amstext}
\usepackage{babel}



\usepackage{tgtermes}
\usepackage{tgheros}
\renewcommand{\ttdefault}{txtt}



\usepackage[Bjarne]{fncychap}
\usepackage{sphinx}

\fvset{fontsize=auto}
\usepackage{geometry}


% Include hyperref last.
\usepackage{hyperref}
% Fix anchor placement for figures with captions.
\usepackage{hypcap}% it must be loaded after hyperref.
% Set up styles of URL: it should be placed after hyperref.
\urlstyle{same}

\addto\captionsenglish{\renewcommand{\contentsname}{Contents:}}

\usepackage{sphinxmessages}
\setcounter{tocdepth}{1}


% Custom LaTeX preamble if needed


\title{Fire Diff}
\date{Aug 30, 2024}
\release{1.0.0}
\author{Christopher Ondrusz}
\newcommand{\sphinxlogo}{\vbox{}}
\renewcommand{\releasename}{Release}
\makeindex
\begin{document}

\ifdefined\shorthandoff
  \ifnum\catcode`\=\string=\active\shorthandoff{=}\fi
  \ifnum\catcode`\"=\active\shorthandoff{"}\fi
\fi

\pagestyle{empty}
\sphinxmaketitle
\pagestyle{plain}
\sphinxtableofcontents
\pagestyle{normal}
\phantomsection\label{\detokenize{index::doc}}


\sphinxstepscope


\chapter{Models}
\label{\detokenize{models:models}}\label{\detokenize{models::doc}}

\section{fireDiff.Models.unet}
\label{\detokenize{models:module-fireDiff.Models.unet}}\label{\detokenize{models:firediff-models-unet}}\index{module@\spxentry{module}!fireDiff.Models.unet@\spxentry{fireDiff.Models.unet}}\index{fireDiff.Models.unet@\spxentry{fireDiff.Models.unet}!module@\spxentry{module}}\index{Bottleneck (class in fireDiff.Models.unet)@\spxentry{Bottleneck}\spxextra{class in fireDiff.Models.unet}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{models:fireDiff.Models.unet.Bottleneck}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{class\DUrole{w}{ }}}\sphinxcode{\sphinxupquote{fireDiff.Models.unet.}}\sphinxbfcode{\sphinxupquote{Bottleneck}}}{\sphinxparam{\DUrole{n}{embed\_dim}\DUrole{o}{=}\DUrole{default_value}{128}}\sphinxparamcomma \sphinxparam{\DUrole{n}{num\_heads}\DUrole{o}{=}\DUrole{default_value}{8}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Bases: \sphinxcode{\sphinxupquote{Module}}

\sphinxAtStartPar
A bottleneck layer with a convolutional block and multi\sphinxhyphen{}head attention,
followed by a 1x1 convolution to reduce the number of channels.


\subsection{Parameters:}
\label{\detokenize{models:parameters}}\begin{description}
\sphinxlineitem{embed\_dim}{[}int, optional, default=128{]}
\sphinxAtStartPar
The dimensionality of the embeddings used in the multi\sphinxhyphen{}head attention.

\sphinxlineitem{num\_heads}{[}int, optional, default=8{]}
\sphinxAtStartPar
The number of heads in the multi\sphinxhyphen{}head attention mechanism.

\end{description}


\subsection{Returns:}
\label{\detokenize{models:returns}}\begin{description}
\sphinxlineitem{torch.Tensor}
\sphinxAtStartPar
The output tensor after the bottleneck, with 128 channels and the
same spatial dimensions as the input.

\end{description}

\sphinxAtStartPar
Initialize internal Module state, shared by both nn.Module and ScriptModule.
\index{forward() (fireDiff.Models.unet.Bottleneck method)@\spxentry{forward()}\spxextra{fireDiff.Models.unet.Bottleneck method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{models:fireDiff.Models.unet.Bottleneck.forward}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{forward}}}{\sphinxparam{\DUrole{n}{x}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Forward pass through the bottleneck layer.


\subsubsection{Parameters:}
\label{\detokenize{models:id1}}\begin{description}
\sphinxlineitem{x}{[}torch.Tensor{]}
\sphinxAtStartPar
The input tensor of shape (batch\_size, 64, height, width).

\end{description}


\subsubsection{Returns:}
\label{\detokenize{models:id2}}\begin{description}
\sphinxlineitem{torch.Tensor}
\sphinxAtStartPar
The output tensor of shape (batch\_size, 128, height, width).

\end{description}

\end{fulllineitems}


\end{fulllineitems}

\index{ConvBlock (class in fireDiff.Models.unet)@\spxentry{ConvBlock}\spxextra{class in fireDiff.Models.unet}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{models:fireDiff.Models.unet.ConvBlock}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{class\DUrole{w}{ }}}\sphinxcode{\sphinxupquote{fireDiff.Models.unet.}}\sphinxbfcode{\sphinxupquote{ConvBlock}}}{\sphinxparam{\DUrole{n}{in\_channels}}\sphinxparamcomma \sphinxparam{\DUrole{n}{out\_channels}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Bases: \sphinxcode{\sphinxupquote{Module}}

\sphinxAtStartPar
A convolutional block that applies two convolutional layers with batch
normalization and activation functions.


\subsection{Parameters:}
\label{\detokenize{models:id3}}\begin{description}
\sphinxlineitem{in\_channels}{[}int{]}
\sphinxAtStartPar
The number of input channels for the convolutional layers.

\sphinxlineitem{out\_channels}{[}int{]}
\sphinxAtStartPar
The number of output channels for the convolutional layers.

\end{description}


\subsection{Returns:}
\label{\detokenize{models:id4}}\begin{description}
\sphinxlineitem{torch.Tensor}
\sphinxAtStartPar
The output tensor after applying the convolutional block, with the
same height and width as the input.

\end{description}

\sphinxAtStartPar
Initialize internal Module state, shared by both nn.Module and ScriptModule.
\index{forward() (fireDiff.Models.unet.ConvBlock method)@\spxentry{forward()}\spxextra{fireDiff.Models.unet.ConvBlock method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{models:fireDiff.Models.unet.ConvBlock.forward}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{forward}}}{\sphinxparam{\DUrole{n}{x}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Forward pass through the convolutional block.


\subsubsection{Parameters:}
\label{\detokenize{models:id5}}\begin{description}
\sphinxlineitem{x}{[}torch.Tensor{]}
\sphinxAtStartPar
The input tensor of shape (batch\_size, in\_channels, height, width).

\end{description}


\subsubsection{Returns:}
\label{\detokenize{models:id6}}\begin{description}
\sphinxlineitem{torch.Tensor}\begin{description}
\sphinxlineitem{The output tensor of shape (batch\_size, out\_channels,}
\sphinxAtStartPar
height, width).

\end{description}

\end{description}

\end{fulllineitems}


\end{fulllineitems}

\index{Decoder (class in fireDiff.Models.unet)@\spxentry{Decoder}\spxextra{class in fireDiff.Models.unet}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{models:fireDiff.Models.unet.Decoder}}
\pysigstartsignatures
\pysigline{\sphinxbfcode{\sphinxupquote{class\DUrole{w}{ }}}\sphinxcode{\sphinxupquote{fireDiff.Models.unet.}}\sphinxbfcode{\sphinxupquote{Decoder}}}
\pysigstopsignatures
\sphinxAtStartPar
Bases: \sphinxcode{\sphinxupquote{Module}}

\sphinxAtStartPar
The decoder part of a U\sphinxhyphen{}Net, which upsamples the input using transposed
convolutions and refines the features using convolutional blocks.


\subsection{Returns:}
\label{\detokenize{models:id7}}\begin{description}
\sphinxlineitem{torch.Tensor}
\sphinxAtStartPar
The final output tensor after the decoder, with 1 channel and the
same spatial dimensions as the original input.

\end{description}

\sphinxAtStartPar
Initialize internal Module state, shared by both nn.Module and ScriptModule.
\index{forward() (fireDiff.Models.unet.Decoder method)@\spxentry{forward()}\spxextra{fireDiff.Models.unet.Decoder method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{models:fireDiff.Models.unet.Decoder.forward}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{forward}}}{\sphinxparam{\DUrole{n}{x}}\sphinxparamcomma \sphinxparam{\DUrole{n}{enc\_features}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Forward pass through the decoder.


\subsubsection{Parameters:}
\label{\detokenize{models:id8}}\begin{description}
\sphinxlineitem{x}{[}torch.Tensor{]}
\sphinxAtStartPar
The input tensor from the bottleneck layer of shape
(batch\_size, 128, height/8, width/8).

\sphinxlineitem{enc\_features}{[}tuple{]}
\sphinxAtStartPar
A tuple of feature maps from the encoder to be concatenated
with the upsampled features at each step.

\end{description}


\subsubsection{Returns:}
\label{\detokenize{models:id9}}\begin{description}
\sphinxlineitem{torch.Tensor}
\sphinxAtStartPar
The output tensor of shape (batch\_size, 1, height, width)
after applying the final GELU activation.

\end{description}

\end{fulllineitems}


\end{fulllineitems}

\index{Encoder (class in fireDiff.Models.unet)@\spxentry{Encoder}\spxextra{class in fireDiff.Models.unet}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{models:fireDiff.Models.unet.Encoder}}
\pysigstartsignatures
\pysigline{\sphinxbfcode{\sphinxupquote{class\DUrole{w}{ }}}\sphinxcode{\sphinxupquote{fireDiff.Models.unet.}}\sphinxbfcode{\sphinxupquote{Encoder}}}
\pysigstopsignatures
\sphinxAtStartPar
Bases: \sphinxcode{\sphinxupquote{Module}}

\sphinxAtStartPar
The encoder part of a U\sphinxhyphen{}Net, which reduces the spatial dimensions
of the input through convolutional blocks and max\sphinxhyphen{}pooling layers.


\subsection{Returns:}
\label{\detokenize{models:id10}}\begin{description}
\sphinxlineitem{tuple :}
\sphinxAtStartPar
A tuple containing:
\sphinxhyphen{} The downsampled output tensor after the final pooling layer.
\sphinxhyphen{} A tuple of feature maps from each convolutional block,
to be used in the decoder for skip connections.

\end{description}

\sphinxAtStartPar
Initialize internal Module state, shared by both nn.Module and ScriptModule.
\index{forward() (fireDiff.Models.unet.Encoder method)@\spxentry{forward()}\spxextra{fireDiff.Models.unet.Encoder method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{models:fireDiff.Models.unet.Encoder.forward}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{forward}}}{\sphinxparam{\DUrole{n}{x}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Forward pass through the encoder.


\subsubsection{Parameters:}
\label{\detokenize{models:id11}}\begin{description}
\sphinxlineitem{x}{[}torch.Tensor{]}
\sphinxAtStartPar
The input tensor of shape (batch\_size, 1, height, width).

\end{description}


\subsubsection{Returns:}
\label{\detokenize{models:id12}}\begin{description}
\sphinxlineitem{tuple :}
\sphinxAtStartPar
A tuple containing:
\sphinxhyphen{} The output tensor after the final pooling layer, of shape
(batch\_size, 64, height/8, width/8).
\sphinxhyphen{} A tuple of tensors containing the output of each convolutional
block before pooling, to be used in the decoder for skip
connections.

\end{description}

\end{fulllineitems}


\end{fulllineitems}

\index{UNet (class in fireDiff.Models.unet)@\spxentry{UNet}\spxextra{class in fireDiff.Models.unet}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{models:fireDiff.Models.unet.UNet}}
\pysigstartsignatures
\pysigline{\sphinxbfcode{\sphinxupquote{class\DUrole{w}{ }}}\sphinxcode{\sphinxupquote{fireDiff.Models.unet.}}\sphinxbfcode{\sphinxupquote{UNet}}}
\pysigstopsignatures
\sphinxAtStartPar
Bases: \sphinxcode{\sphinxupquote{Module}}

\sphinxAtStartPar
A U\sphinxhyphen{}Net model combining an encoder, a bottleneck with an attention
mechanism, and a decoder to produce a final output with the same
spatial dimensions as the input.


\subsection{Returns:}
\label{\detokenize{models:id13}}\begin{description}
\sphinxlineitem{torch.Tensor}
\sphinxAtStartPar
The final output tensor after passing through the U\sphinxhyphen{}Net, with
1 channel and the same spatial dimensions as the input.

\end{description}

\sphinxAtStartPar
Initialize internal Module state, shared by both nn.Module and ScriptModule.
\index{forward() (fireDiff.Models.unet.UNet method)@\spxentry{forward()}\spxextra{fireDiff.Models.unet.UNet method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{models:fireDiff.Models.unet.UNet.forward}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{forward}}}{\sphinxparam{\DUrole{n}{x}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Forward pass through the U\sphinxhyphen{}Net model.


\subsubsection{Parameters:}
\label{\detokenize{models:id14}}\begin{description}
\sphinxlineitem{x}{[}torch.Tensor{]}
\sphinxAtStartPar
The input tensor of shape (batch\_size, 1, height, width).

\end{description}


\subsubsection{Returns:}
\label{\detokenize{models:id15}}\begin{description}
\sphinxlineitem{torch.Tensor}
\sphinxAtStartPar
The output tensor of shape (batch\_size, 1, height, width)
after passing through the entire U\sphinxhyphen{}Net.

\end{description}

\end{fulllineitems}


\end{fulllineitems}



\bigskip\hrule\bigskip



\section{fireDiff.Models.unet\_predictor}
\label{\detokenize{models:module-fireDiff.Models.unet_predictor}}\label{\detokenize{models:firediff-models-unet-predictor}}\index{module@\spxentry{module}!fireDiff.Models.unet\_predictor@\spxentry{fireDiff.Models.unet\_predictor}}\index{fireDiff.Models.unet\_predictor@\spxentry{fireDiff.Models.unet\_predictor}!module@\spxentry{module}}\index{Bottleneck (class in fireDiff.Models.unet\_predictor)@\spxentry{Bottleneck}\spxextra{class in fireDiff.Models.unet\_predictor}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{models:fireDiff.Models.unet_predictor.Bottleneck}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{class\DUrole{w}{ }}}\sphinxcode{\sphinxupquote{fireDiff.Models.unet\_predictor.}}\sphinxbfcode{\sphinxupquote{Bottleneck}}}{\sphinxparam{\DUrole{n}{embed\_dim}\DUrole{o}{=}\DUrole{default_value}{128}}\sphinxparamcomma \sphinxparam{\DUrole{n}{num\_heads}\DUrole{o}{=}\DUrole{default_value}{8}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Bases: \sphinxcode{\sphinxupquote{Module}}

\sphinxAtStartPar
Initialize internal Module state, shared by both nn.Module and ScriptModule.
\index{forward() (fireDiff.Models.unet\_predictor.Bottleneck method)@\spxentry{forward()}\spxextra{fireDiff.Models.unet\_predictor.Bottleneck method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{models:fireDiff.Models.unet_predictor.Bottleneck.forward}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{forward}}}{\sphinxparam{\DUrole{n}{x}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Define the computation performed at every call.

\sphinxAtStartPar
Should be overridden by all subclasses.

\begin{sphinxadmonition}{note}{Note:}
\sphinxAtStartPar
Although the recipe for forward pass needs to be defined within
this function, one should call the \sphinxcode{\sphinxupquote{Module}} instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.
\end{sphinxadmonition}

\end{fulllineitems}


\end{fulllineitems}

\index{ConvBlock (class in fireDiff.Models.unet\_predictor)@\spxentry{ConvBlock}\spxextra{class in fireDiff.Models.unet\_predictor}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{models:fireDiff.Models.unet_predictor.ConvBlock}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{class\DUrole{w}{ }}}\sphinxcode{\sphinxupquote{fireDiff.Models.unet\_predictor.}}\sphinxbfcode{\sphinxupquote{ConvBlock}}}{\sphinxparam{\DUrole{n}{in\_channels}}\sphinxparamcomma \sphinxparam{\DUrole{n}{out\_channels}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Bases: \sphinxcode{\sphinxupquote{Module}}

\sphinxAtStartPar
A convolutional block consisting of two convolutional layers, each
followed by a ReLU activation. The block preserves the spatial dimensions
of the input.


\subsection{Parameters:}
\label{\detokenize{models:id16}}\begin{description}
\sphinxlineitem{in\_channels}{[}int{]}
\sphinxAtStartPar
The number of input channels for the convolutional layers.

\sphinxlineitem{out\_channels}{[}int{]}
\sphinxAtStartPar
The number of output channels for the convolutional layers.

\end{description}


\subsection{Returns:}
\label{\detokenize{models:id17}}
\sphinxAtStartPar
None

\sphinxAtStartPar
Initialize internal Module state, shared by both nn.Module and ScriptModule.
\index{forward() (fireDiff.Models.unet\_predictor.ConvBlock method)@\spxentry{forward()}\spxextra{fireDiff.Models.unet\_predictor.ConvBlock method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{models:fireDiff.Models.unet_predictor.ConvBlock.forward}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{forward}}}{\sphinxparam{\DUrole{n}{x}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Define the computation performed at every call.

\sphinxAtStartPar
Should be overridden by all subclasses.

\begin{sphinxadmonition}{note}{Note:}
\sphinxAtStartPar
Although the recipe for forward pass needs to be defined within
this function, one should call the \sphinxcode{\sphinxupquote{Module}} instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.
\end{sphinxadmonition}

\end{fulllineitems}


\end{fulllineitems}

\index{Decoder (class in fireDiff.Models.unet\_predictor)@\spxentry{Decoder}\spxextra{class in fireDiff.Models.unet\_predictor}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{models:fireDiff.Models.unet_predictor.Decoder}}
\pysigstartsignatures
\pysigline{\sphinxbfcode{\sphinxupquote{class\DUrole{w}{ }}}\sphinxcode{\sphinxupquote{fireDiff.Models.unet\_predictor.}}\sphinxbfcode{\sphinxupquote{Decoder}}}
\pysigstopsignatures
\sphinxAtStartPar
Bases: \sphinxcode{\sphinxupquote{Module}}

\sphinxAtStartPar
Initialize internal Module state, shared by both nn.Module and ScriptModule.
\index{forward() (fireDiff.Models.unet\_predictor.Decoder method)@\spxentry{forward()}\spxextra{fireDiff.Models.unet\_predictor.Decoder method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{models:fireDiff.Models.unet_predictor.Decoder.forward}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{forward}}}{\sphinxparam{\DUrole{n}{x}}\sphinxparamcomma \sphinxparam{\DUrole{n}{enc\_features}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Define the computation performed at every call.

\sphinxAtStartPar
Should be overridden by all subclasses.

\begin{sphinxadmonition}{note}{Note:}
\sphinxAtStartPar
Although the recipe for forward pass needs to be defined within
this function, one should call the \sphinxcode{\sphinxupquote{Module}} instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.
\end{sphinxadmonition}

\end{fulllineitems}


\end{fulllineitems}

\index{Encoder (class in fireDiff.Models.unet\_predictor)@\spxentry{Encoder}\spxextra{class in fireDiff.Models.unet\_predictor}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{models:fireDiff.Models.unet_predictor.Encoder}}
\pysigstartsignatures
\pysigline{\sphinxbfcode{\sphinxupquote{class\DUrole{w}{ }}}\sphinxcode{\sphinxupquote{fireDiff.Models.unet\_predictor.}}\sphinxbfcode{\sphinxupquote{Encoder}}}
\pysigstopsignatures
\sphinxAtStartPar
Bases: \sphinxcode{\sphinxupquote{Module}}

\sphinxAtStartPar
Initialize internal Module state, shared by both nn.Module and ScriptModule.
\index{forward() (fireDiff.Models.unet\_predictor.Encoder method)@\spxentry{forward()}\spxextra{fireDiff.Models.unet\_predictor.Encoder method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{models:fireDiff.Models.unet_predictor.Encoder.forward}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{forward}}}{\sphinxparam{\DUrole{n}{x}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Define the computation performed at every call.

\sphinxAtStartPar
Should be overridden by all subclasses.

\begin{sphinxadmonition}{note}{Note:}
\sphinxAtStartPar
Although the recipe for forward pass needs to be defined within
this function, one should call the \sphinxcode{\sphinxupquote{Module}} instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.
\end{sphinxadmonition}

\end{fulllineitems}


\end{fulllineitems}

\index{PredictorUNet (class in fireDiff.Models.unet\_predictor)@\spxentry{PredictorUNet}\spxextra{class in fireDiff.Models.unet\_predictor}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{models:fireDiff.Models.unet_predictor.PredictorUNet}}
\pysigstartsignatures
\pysigline{\sphinxbfcode{\sphinxupquote{class\DUrole{w}{ }}}\sphinxcode{\sphinxupquote{fireDiff.Models.unet\_predictor.}}\sphinxbfcode{\sphinxupquote{PredictorUNet}}}
\pysigstopsignatures
\sphinxAtStartPar
Bases: \sphinxcode{\sphinxupquote{Module}}

\sphinxAtStartPar
Initialize internal Module state, shared by both nn.Module and ScriptModule.
\index{forward() (fireDiff.Models.unet\_predictor.PredictorUNet method)@\spxentry{forward()}\spxextra{fireDiff.Models.unet\_predictor.PredictorUNet method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{models:fireDiff.Models.unet_predictor.PredictorUNet.forward}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{forward}}}{\sphinxparam{\DUrole{n}{x}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Define the computation performed at every call.

\sphinxAtStartPar
Should be overridden by all subclasses.

\begin{sphinxadmonition}{note}{Note:}
\sphinxAtStartPar
Although the recipe for forward pass needs to be defined within
this function, one should call the \sphinxcode{\sphinxupquote{Module}} instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.
\end{sphinxadmonition}

\end{fulllineitems}


\end{fulllineitems}



\bigskip\hrule\bigskip



\section{fireDiff.Models.diffusionmodel}
\label{\detokenize{models:module-fireDiff.Models.diffusionmodel}}\label{\detokenize{models:firediff-models-diffusionmodel}}\index{module@\spxentry{module}!fireDiff.Models.diffusionmodel@\spxentry{fireDiff.Models.diffusionmodel}}\index{fireDiff.Models.diffusionmodel@\spxentry{fireDiff.Models.diffusionmodel}!module@\spxentry{module}}\index{DiffusionModel (class in fireDiff.Models.diffusionmodel)@\spxentry{DiffusionModel}\spxextra{class in fireDiff.Models.diffusionmodel}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{models:fireDiff.Models.diffusionmodel.DiffusionModel}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{class\DUrole{w}{ }}}\sphinxcode{\sphinxupquote{fireDiff.Models.diffusionmodel.}}\sphinxbfcode{\sphinxupquote{DiffusionModel}}}{\sphinxparam{\DUrole{n}{model}}\sphinxparamcomma \sphinxparam{\DUrole{n}{lambda\_start}\DUrole{o}{=}\DUrole{default_value}{1.0}}\sphinxparamcomma \sphinxparam{\DUrole{n}{lambda\_end}\DUrole{o}{=}\DUrole{default_value}{0.0}}\sphinxparamcomma \sphinxparam{\DUrole{n}{device}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}cpu\textquotesingle{}}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Bases: \sphinxcode{\sphinxupquote{Module}}

\sphinxAtStartPar
A diffusion model that uses a base neural network model (e.g., UNet)
to perform denoising and sampling tasks. The model can be trained using
a specified noise schedule.


\subsection{Parameters:}
\label{\detokenize{models:id18}}\begin{description}
\sphinxlineitem{model}{[}nn.Module{]}
\sphinxAtStartPar
The base neural network model architecture (e.g., UNet).

\sphinxlineitem{lambda\_start}{[}float, optional, default=1.0{]}
\sphinxAtStartPar
The starting value for the lambda schedule.

\sphinxlineitem{lambda\_end}{[}float, optional, default=0.0{]}
\sphinxAtStartPar
The ending value for the lambda schedule.

\sphinxlineitem{device}{[}str, optional, default=’cuda’ if torch.cuda.is\_available() else ‘cpu’ \# noqa{]}
\sphinxAtStartPar
The device to run the model on (‘cuda’ or ‘cpu’).

\end{description}


\subsection{Returns:}
\label{\detokenize{models:id19}}
\sphinxAtStartPar
None

\sphinxAtStartPar
Initialize internal Module state, shared by both nn.Module and ScriptModule.
\index{diffusion\_sampler() (fireDiff.Models.diffusionmodel.DiffusionModel method)@\spxentry{diffusion\_sampler()}\spxextra{fireDiff.Models.diffusionmodel.DiffusionModel method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{models:fireDiff.Models.diffusionmodel.DiffusionModel.diffusion_sampler}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{diffusion\_sampler}}}{\sphinxparam{\DUrole{n}{x\_t}}\sphinxparamcomma \sphinxparam{\DUrole{n}{num\_steps}\DUrole{o}{=}\DUrole{default_value}{50}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Generates samples from the diffusion model.


\subsubsection{Parameters:}
\label{\detokenize{models:id20}}\begin{description}
\sphinxlineitem{x\_t}{[}torch.Tensor{]}
\sphinxAtStartPar
The input tensor representing the noisy data to be denoised.

\sphinxlineitem{num\_steps}{[}int, optional, default=50{]}
\sphinxAtStartPar
The number of sampling steps to perform.

\end{description}


\subsubsection{Returns:}
\label{\detokenize{models:id21}}\begin{description}
\sphinxlineitem{torch.Tensor}
\sphinxAtStartPar
The denoised output tensor generated by the model.

\end{description}

\end{fulllineitems}

\index{load\_model() (fireDiff.Models.diffusionmodel.DiffusionModel method)@\spxentry{load\_model()}\spxextra{fireDiff.Models.diffusionmodel.DiffusionModel method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{models:fireDiff.Models.diffusionmodel.DiffusionModel.load_model}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{load\_model}}}{\sphinxparam{\DUrole{n}{path}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Loads the model’s state dictionary from a specified path.


\subsubsection{Parameters:}
\label{\detokenize{models:id22}}\begin{description}
\sphinxlineitem{path}{[}str{]}
\sphinxAtStartPar
The file path from which to load the model’s state dictionary.

\end{description}


\subsubsection{Returns:}
\label{\detokenize{models:id23}}
\sphinxAtStartPar
None

\end{fulllineitems}

\index{save\_model() (fireDiff.Models.diffusionmodel.DiffusionModel method)@\spxentry{save\_model()}\spxextra{fireDiff.Models.diffusionmodel.DiffusionModel method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{models:fireDiff.Models.diffusionmodel.DiffusionModel.save_model}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{save\_model}}}{\sphinxparam{\DUrole{n}{path}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Saves the model’s state dictionary to a specified path.


\subsubsection{Parameters:}
\label{\detokenize{models:id24}}\begin{description}
\sphinxlineitem{path}{[}str{]}
\sphinxAtStartPar
The file path where the model’s state dictionary will be saved.

\end{description}


\subsubsection{Returns:}
\label{\detokenize{models:id25}}
\sphinxAtStartPar
None

\end{fulllineitems}

\index{train\_model() (fireDiff.Models.diffusionmodel.DiffusionModel method)@\spxentry{train\_model()}\spxextra{fireDiff.Models.diffusionmodel.DiffusionModel method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{models:fireDiff.Models.diffusionmodel.DiffusionModel.train_model}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{train\_model}}}{\sphinxparam{\DUrole{n}{dataloader}}\sphinxparamcomma \sphinxparam{\DUrole{n}{train\_steps}\DUrole{o}{=}\DUrole{default_value}{1000}}\sphinxparamcomma \sphinxparam{\DUrole{n}{epochs}\DUrole{o}{=}\DUrole{default_value}{50}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Trains the diffusion model using the provided dataloader.


\subsubsection{Parameters:}
\label{\detokenize{models:id26}}\begin{description}
\sphinxlineitem{dataloader}{[}torch.utils.data.DataLoader{]}
\sphinxAtStartPar
The dataloader providing batches of data for training.

\sphinxlineitem{train\_steps}{[}int, optional, default=1000{]}
\sphinxAtStartPar
The number of diffusion steps used in training.

\sphinxlineitem{epochs}{[}int, optional, default=50{]}
\sphinxAtStartPar
The number of epochs for which to train the model.

\end{description}


\subsubsection{Returns:}
\label{\detokenize{models:id27}}
\sphinxAtStartPar
None

\end{fulllineitems}


\end{fulllineitems}



\bigskip\hrule\bigskip

\index{module@\spxentry{module}!fireDiff.Models.deterministicmodel@\spxentry{fireDiff.Models.deterministicmodel}}\index{fireDiff.Models.deterministicmodel@\spxentry{fireDiff.Models.deterministicmodel}!module@\spxentry{module}}\index{PredictionModel (class in fireDiff.Models.deterministicmodel)@\spxentry{PredictionModel}\spxextra{class in fireDiff.Models.deterministicmodel}}\phantomsection\label{\detokenize{models:module-fireDiff.Models.deterministicmodel}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{models:fireDiff.Models.deterministicmodel.PredictionModel}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{class\DUrole{w}{ }}}\sphinxcode{\sphinxupquote{fireDiff.Models.deterministicmodel.}}\sphinxbfcode{\sphinxupquote{PredictionModel}}}{\sphinxparam{\DUrole{n}{model}}\sphinxparamcomma \sphinxparam{\DUrole{n}{device}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}cpu\textquotesingle{}}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Bases: \sphinxcode{\sphinxupquote{Module}}

\sphinxAtStartPar
A wrapper class for a neural network model that facilitates training,
validation, and saving/loading model checkpoints. The model is designed
to run on either a CPU or GPU.


\subsection{Parameters:}
\label{\detokenize{models:id28}}\begin{description}
\sphinxlineitem{model}{[}nn.Module{]}
\sphinxAtStartPar
The base model architecture (e.g., UNet).

\sphinxlineitem{device}{[}str, optional, default=’cuda’ if torch.cuda.is\_available() else ‘cpu’ \# noqa{]}
\sphinxAtStartPar
The device to run the model on (‘cuda’ or ‘cpu’).

\end{description}


\subsection{Returns:}
\label{\detokenize{models:id29}}
\sphinxAtStartPar
None
\index{load\_model() (fireDiff.Models.deterministicmodel.PredictionModel method)@\spxentry{load\_model()}\spxextra{fireDiff.Models.deterministicmodel.PredictionModel method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{models:fireDiff.Models.deterministicmodel.PredictionModel.load_model}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{load\_model}}}{\sphinxparam{\DUrole{n}{path}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Loads the model’s state dictionary from a specified file.


\subsubsection{Parameters:}
\label{\detokenize{models:id30}}\begin{description}
\sphinxlineitem{path}{[}str{]}
\sphinxAtStartPar
The file path from which to load the model’s state dictionary.

\end{description}


\subsubsection{Returns:}
\label{\detokenize{models:id31}}
\sphinxAtStartPar
None

\end{fulllineitems}

\index{save\_model() (fireDiff.Models.deterministicmodel.PredictionModel method)@\spxentry{save\_model()}\spxextra{fireDiff.Models.deterministicmodel.PredictionModel method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{models:fireDiff.Models.deterministicmodel.PredictionModel.save_model}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{save\_model}}}{\sphinxparam{\DUrole{n}{path}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Saves the model’s state dictionary to a specified file.


\subsubsection{Parameters:}
\label{\detokenize{models:id32}}\begin{description}
\sphinxlineitem{path}{[}str{]}
\sphinxAtStartPar
The file path where the model’s state dictionary will be saved.

\end{description}


\subsubsection{Returns:}
\label{\detokenize{models:id33}}
\sphinxAtStartPar
None

\end{fulllineitems}

\index{train\_model() (fireDiff.Models.deterministicmodel.PredictionModel method)@\spxentry{train\_model()}\spxextra{fireDiff.Models.deterministicmodel.PredictionModel method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{models:fireDiff.Models.deterministicmodel.PredictionModel.train_model}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{train\_model}}}{\sphinxparam{\DUrole{n}{tdataloader}}\sphinxparamcomma \sphinxparam{\DUrole{n}{vdataloader}}\sphinxparamcomma \sphinxparam{\DUrole{n}{epochs}\DUrole{o}{=}\DUrole{default_value}{50}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Trains the model over a specified number of epochs, and evaluates
it on a validation dataset after each epoch.


\subsubsection{Parameters:}
\label{\detokenize{models:id34}}\begin{description}
\sphinxlineitem{tdataloader}{[}torch.utils.data.DataLoader{]}
\sphinxAtStartPar
The data loader providing the training data.

\sphinxlineitem{vdataloader}{[}torch.utils.data.DataLoader{]}
\sphinxAtStartPar
The data loader providing the validation data.

\sphinxlineitem{epochs}{[}int, optional, default=50{]}
\sphinxAtStartPar
The number of epochs to train the model.

\end{description}


\subsubsection{Returns:}
\label{\detokenize{models:id35}}\begin{description}
\sphinxlineitem{tuple}
\sphinxAtStartPar
A tuple containing two lists: the training loss and validation loss
for each epoch.

\end{description}

\end{fulllineitems}

\index{train\_step() (fireDiff.Models.deterministicmodel.PredictionModel method)@\spxentry{train\_step()}\spxextra{fireDiff.Models.deterministicmodel.PredictionModel method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{models:fireDiff.Models.deterministicmodel.PredictionModel.train_step}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{train\_step}}}{\sphinxparam{\DUrole{n}{optimizer}}\sphinxparamcomma \sphinxparam{\DUrole{n}{criterion}}\sphinxparamcomma \sphinxparam{\DUrole{n}{data\_loader}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Performs a single training step, including forward pass, loss
computation, and backpropagation for the entire dataset provided
by the data loader.


\subsubsection{Parameters:}
\label{\detokenize{models:id36}}\begin{description}
\sphinxlineitem{optimizer}{[}torch.optim.Optimizer{]}
\sphinxAtStartPar
The optimizer used to update the model’s weights.

\sphinxlineitem{criterion}{[}nn.Module{]}
\sphinxAtStartPar
The loss function used to compute the loss.

\sphinxlineitem{data\_loader}{[}torch.utils.data.DataLoader{]}
\sphinxAtStartPar
The data loader providing the training data.

\end{description}


\subsubsection{Returns:}
\label{\detokenize{models:id37}}\begin{description}
\sphinxlineitem{float}
\sphinxAtStartPar
The average training loss over the entire dataset.

\end{description}

\end{fulllineitems}

\index{validate() (fireDiff.Models.deterministicmodel.PredictionModel method)@\spxentry{validate()}\spxextra{fireDiff.Models.deterministicmodel.PredictionModel method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{models:fireDiff.Models.deterministicmodel.PredictionModel.validate}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{validate}}}{\sphinxparam{\DUrole{n}{criterion}}\sphinxparamcomma \sphinxparam{\DUrole{n}{data\_loader}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Evaluates the model on a validation dataset without updating model
weights.


\subsubsection{Parameters:}
\label{\detokenize{models:id38}}\begin{description}
\sphinxlineitem{criterion}{[}nn.Module{]}
\sphinxAtStartPar
The loss function used to compute the loss.

\sphinxlineitem{data\_loader}{[}torch.utils.data.DataLoader{]}
\sphinxAtStartPar
The data loader providing the validation data.

\end{description}


\subsubsection{Returns:}
\label{\detokenize{models:id39}}\begin{description}
\sphinxlineitem{float}
\sphinxAtStartPar
The average validation loss over the entire dataset.

\end{description}

\end{fulllineitems}


\end{fulllineitems}



\bigskip\hrule\bigskip



\section{fireDiff.Models.cae}
\label{\detokenize{models:module-fireDiff.Models.cae}}\label{\detokenize{models:firediff-models-cae}}\index{module@\spxentry{module}!fireDiff.Models.cae@\spxentry{fireDiff.Models.cae}}\index{fireDiff.Models.cae@\spxentry{fireDiff.Models.cae}!module@\spxentry{module}}\index{Autoencoder (class in fireDiff.Models.cae)@\spxentry{Autoencoder}\spxextra{class in fireDiff.Models.cae}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{models:fireDiff.Models.cae.Autoencoder}}
\pysigstartsignatures
\pysigline{\sphinxbfcode{\sphinxupquote{class\DUrole{w}{ }}}\sphinxcode{\sphinxupquote{fireDiff.Models.cae.}}\sphinxbfcode{\sphinxupquote{Autoencoder}}}
\pysigstopsignatures
\sphinxAtStartPar
Bases: \sphinxcode{\sphinxupquote{Module}}

\sphinxAtStartPar
A convolutional autoencoder neural network for image compression and
reconstruction.
The autoencoder consists of an encoder that compresses the input image
into a lower\sphinxhyphen{}dimensional representation and a decoder that reconstructs
the image from this representation.


\subsection{Parameters:}
\label{\detokenize{models:id40}}
\sphinxAtStartPar
None


\subsection{Returns:}
\label{\detokenize{models:id41}}
\sphinxAtStartPar
None

\sphinxAtStartPar
Initialize internal Module state, shared by both nn.Module and ScriptModule.
\index{forward() (fireDiff.Models.cae.Autoencoder method)@\spxentry{forward()}\spxextra{fireDiff.Models.cae.Autoencoder method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{models:fireDiff.Models.cae.Autoencoder.forward}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{forward}}}{\sphinxparam{\DUrole{n}{x}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Defines the forward pass of the autoencoder, where the input image
is passed through the encoder to obtain a compressed representation
and then through the decoder to reconstruct the image.


\subsubsection{Parameters:}
\label{\detokenize{models:id42}}\begin{description}
\sphinxlineitem{x}{[}torch.Tensor{]}
\sphinxAtStartPar
The input tensor of shape (batch\_size, 1, height, width)
representing grayscale images.

\end{description}


\subsubsection{Returns:}
\label{\detokenize{models:id43}}\begin{description}
\sphinxlineitem{torch.Tensor}
\sphinxAtStartPar
The reconstructed image tensor of the same shape as the input.

\end{description}

\end{fulllineitems}


\end{fulllineitems}



\bigskip\hrule\bigskip



\section{fireDiff.Models.fcae}
\label{\detokenize{models:module-fireDiff.Models.fcae}}\label{\detokenize{models:firediff-models-fcae}}\index{module@\spxentry{module}!fireDiff.Models.fcae@\spxentry{fireDiff.Models.fcae}}\index{fireDiff.Models.fcae@\spxentry{fireDiff.Models.fcae}!module@\spxentry{module}}\index{FullyConnectedAutoencoder (class in fireDiff.Models.fcae)@\spxentry{FullyConnectedAutoencoder}\spxextra{class in fireDiff.Models.fcae}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{models:fireDiff.Models.fcae.FullyConnectedAutoencoder}}
\pysigstartsignatures
\pysigline{\sphinxbfcode{\sphinxupquote{class\DUrole{w}{ }}}\sphinxcode{\sphinxupquote{fireDiff.Models.fcae.}}\sphinxbfcode{\sphinxupquote{FullyConnectedAutoencoder}}}
\pysigstopsignatures
\sphinxAtStartPar
Bases: \sphinxcode{\sphinxupquote{Module}}

\sphinxAtStartPar
A fully connected autoencoder neural network for image compression and
reconstruction.
The autoencoder compresses the input image into a lower\sphinxhyphen{}dimensional
representation using fully connected layers and then reconstructs the
image from this representation.


\subsection{Parameters:}
\label{\detokenize{models:id44}}
\sphinxAtStartPar
None


\subsection{Returns:}
\label{\detokenize{models:id45}}
\sphinxAtStartPar
None

\sphinxAtStartPar
Initialize internal Module state, shared by both nn.Module and ScriptModule.
\index{forward() (fireDiff.Models.fcae.FullyConnectedAutoencoder method)@\spxentry{forward()}\spxextra{fireDiff.Models.fcae.FullyConnectedAutoencoder method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{models:fireDiff.Models.fcae.FullyConnectedAutoencoder.forward}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{forward}}}{\sphinxparam{\DUrole{n}{x}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Defines the forward pass of the fully connected autoencoder. The input
image is first flattened, then passed through the encoder to obtain a
compressed representation, and finally passed through the decoder to
reconstruct the image.


\subsubsection{Parameters:}
\label{\detokenize{models:id46}}\begin{description}
\sphinxlineitem{x}{[}torch.Tensor{]}
\sphinxAtStartPar
The input tensor of shape (batch\_size, 1, 128, 128) representing
grayscale images.

\end{description}


\subsubsection{Returns:}
\label{\detokenize{models:id47}}\begin{description}
\sphinxlineitem{torch.Tensor}
\sphinxAtStartPar
The reconstructed image tensor of shape (batch\_size, 1, 128, 128).

\end{description}

\end{fulllineitems}


\end{fulllineitems}



\bigskip\hrule\bigskip



\section{fireDiff.Models.utils}
\label{\detokenize{models:module-fireDiff.Models.utils}}\label{\detokenize{models:firediff-models-utils}}\index{module@\spxentry{module}!fireDiff.Models.utils@\spxentry{fireDiff.Models.utils}}\index{fireDiff.Models.utils@\spxentry{fireDiff.Models.utils}!module@\spxentry{module}}\index{compute\_alpha\_sigma() (in module fireDiff.Models.utils)@\spxentry{compute\_alpha\_sigma()}\spxextra{in module fireDiff.Models.utils}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{models:fireDiff.Models.utils.compute_alpha_sigma}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{fireDiff.Models.utils.}}\sphinxbfcode{\sphinxupquote{compute\_alpha\_sigma}}}{\sphinxparam{\DUrole{n}{lambda\_tau}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Compute the alpha and sigma values used in the diffusion process from the
given lambda values.


\subsection{Parameters:}
\label{\detokenize{models:id48}}\begin{description}
\sphinxlineitem{lambda\_tau}{[}torch.Tensor{]}
\sphinxAtStartPar
A tensor containing lambda values, which are used to calculate the
alpha and sigma values.

\end{description}


\subsection{Returns:}
\label{\detokenize{models:id49}}\begin{description}
\sphinxlineitem{tuple of torch.Tensor}
\sphinxAtStartPar
A tuple containing two tensors:
\sphinxhyphen{} \sphinxtitleref{alpha\_tau}: The calculated alpha values, which are used in the
diffusion process.
\sphinxhyphen{} \sphinxtitleref{sigma\_tau}: The calculated sigma values, representing the standard
deviation of the noise added during diffusion.

\end{description}


\subsection{Example:}
\label{\detokenize{models:example}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{lambda\PYGZus{}tau} \PYG{o}{=} \PYG{n}{torch}\PYG{o}{.}\PYG{n}{tensor}\PYG{p}{(}\PYG{p}{[}\PYG{l+m+mf}{0.5}\PYG{p}{,} \PYG{l+m+mf}{1.0}\PYG{p}{,} \PYG{l+m+mf}{1.5}\PYG{p}{]}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{alpha\PYGZus{}tau}\PYG{p}{,} \PYG{n}{sigma\PYGZus{}tau} \PYG{o}{=} \PYG{n}{compute\PYGZus{}alpha\PYGZus{}sigma}\PYG{p}{(}\PYG{n}{lambda\PYGZus{}tau}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{alpha\PYGZus{}tau}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{sigma\PYGZus{}tau}\PYG{p}{)}
\end{sphinxVerbatim}

\end{fulllineitems}

\index{loss\_function() (in module fireDiff.Models.utils)@\spxentry{loss\_function()}\spxextra{in module fireDiff.Models.utils}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{models:fireDiff.Models.utils.loss_function}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{fireDiff.Models.utils.}}\sphinxbfcode{\sphinxupquote{loss\_function}}}{\sphinxparam{\DUrole{n}{v\_tau}}\sphinxparamcomma \sphinxparam{\DUrole{n}{v\_hat}}\sphinxparamcomma \sphinxparam{\DUrole{n}{lambda\_tau}}\sphinxparamcomma \sphinxparam{\DUrole{n}{t}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Compute the loss for training a diffusion model, considering the predicted
and true noise.


\subsection{Parameters:}
\label{\detokenize{models:id50}}\begin{description}
\sphinxlineitem{v\_tau}{[}torch.Tensor{]}
\sphinxAtStartPar
The true noise tensor used in the diffusion process.

\sphinxlineitem{v\_hat}{[}torch.Tensor{]}
\sphinxAtStartPar
The predicted noise tensor by the model.

\sphinxlineitem{lambda\_tau}{[}torch.Tensor{]}
\sphinxAtStartPar
A tensor containing lambda values for each timestep.

\sphinxlineitem{t}{[}torch.Tensor{]}
\sphinxAtStartPar
A tensor of timesteps at which the loss is computed.

\end{description}


\subsection{Returns:}
\label{\detokenize{models:id51}}\begin{description}
\sphinxlineitem{torch.Tensor}
\sphinxAtStartPar
The computed loss value, which is used to optimize the diffusion model
during training.

\end{description}


\subsection{Example:}
\label{\detokenize{models:id52}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{v\PYGZus{}tau} \PYG{o}{=} \PYG{n}{torch}\PYG{o}{.}\PYG{n}{randn}\PYG{p}{(}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{3}\PYG{p}{,} \PYG{l+m+mi}{32}\PYG{p}{,} \PYG{l+m+mi}{32}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{v\PYGZus{}hat} \PYG{o}{=} \PYG{n}{torch}\PYG{o}{.}\PYG{n}{randn}\PYG{p}{(}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{3}\PYG{p}{,} \PYG{l+m+mi}{32}\PYG{p}{,} \PYG{l+m+mi}{32}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{lambda\PYGZus{}tau} \PYG{o}{=} \PYG{n}{torch}\PYG{o}{.}\PYG{n}{linspace}\PYG{p}{(}\PYG{l+m+mf}{0.1}\PYG{p}{,} \PYG{l+m+mf}{0.9}\PYG{p}{,} \PYG{l+m+mi}{50}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{t} \PYG{o}{=} \PYG{n}{torch}\PYG{o}{.}\PYG{n}{tensor}\PYG{p}{(}\PYG{p}{[}\PYG{l+m+mi}{10}\PYG{p}{]}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{loss} \PYG{o}{=} \PYG{n}{loss\PYGZus{}function}\PYG{p}{(}\PYG{n}{v\PYGZus{}tau}\PYG{p}{,} \PYG{n}{v\PYGZus{}hat}\PYG{p}{,} \PYG{n}{lambda\PYGZus{}tau}\PYG{p}{,} \PYG{n}{t}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{loss}\PYG{o}{.}\PYG{n}{item}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}
\end{sphinxVerbatim}

\end{fulllineitems}

\index{noise\_schedule() (in module fireDiff.Models.utils)@\spxentry{noise\_schedule()}\spxextra{in module fireDiff.Models.utils}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{models:fireDiff.Models.utils.noise_schedule}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{fireDiff.Models.utils.}}\sphinxbfcode{\sphinxupquote{noise\_schedule}}}{\sphinxparam{\DUrole{n}{timesteps}}\sphinxparamcomma \sphinxparam{\DUrole{n}{schedule\_type}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}linear\textquotesingle{}}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Generate a noise schedule based on the specified type and number of
timesteps.


\subsection{Parameters:}
\label{\detokenize{models:id53}}\begin{description}
\sphinxlineitem{timesteps}{[}int{]}
\sphinxAtStartPar
The number of timesteps for which to generate the noise schedule.

\sphinxlineitem{schedule\_type}{[}str, optional{]}
\sphinxAtStartPar
The type of noise schedule to generate. Supported types are ‘linear’
and ‘cosine’.
Default is ‘linear’.

\end{description}


\subsection{Returns:}
\label{\detokenize{models:id54}}\begin{description}
\sphinxlineitem{torch.Tensor}
\sphinxAtStartPar
A tensor containing the noise schedule values for each timestep.

\end{description}


\subsection{Raises:}
\label{\detokenize{models:raises}}\begin{description}
\sphinxlineitem{ValueError}
\sphinxAtStartPar
If the \sphinxtitleref{schedule\_type} is not ‘linear’ or ‘cosine’.

\end{description}


\subsection{Example:}
\label{\detokenize{models:id55}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{timesteps} \PYG{o}{=} \PYG{l+m+mi}{50}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{schedule} \PYG{o}{=} \PYG{n}{noise\PYGZus{}schedule}\PYG{p}{(}\PYG{n}{timesteps}\PYG{p}{,} \PYG{n}{schedule\PYGZus{}type}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{cosine}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{schedule}\PYG{p}{)}
\end{sphinxVerbatim}

\end{fulllineitems}

\index{surrogate\_target() (in module fireDiff.Models.utils)@\spxentry{surrogate\_target()}\spxextra{in module fireDiff.Models.utils}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{models:fireDiff.Models.utils.surrogate_target}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{fireDiff.Models.utils.}}\sphinxbfcode{\sphinxupquote{surrogate\_target}}}{\sphinxparam{\DUrole{n}{x\_t}}\sphinxparamcomma \sphinxparam{\DUrole{n}{t}}\sphinxparamcomma \sphinxparam{\DUrole{n}{alpha}}\sphinxparamcomma \sphinxparam{\DUrole{n}{sigma}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Calculate the surrogate target used in the training of diffusion models.


\subsection{Parameters:}
\label{\detokenize{models:id56}}\begin{description}
\sphinxlineitem{x\_t}{[}torch.Tensor{]}
\sphinxAtStartPar
The diffused tensor at timestep \sphinxtitleref{t}.

\sphinxlineitem{t}{[}int{]}
\sphinxAtStartPar
The current timestep.

\sphinxlineitem{alpha}{[}torch.Tensor{]}
\sphinxAtStartPar
A tensor containing alpha values for each timestep.

\sphinxlineitem{sigma}{[}torch.Tensor{]}
\sphinxAtStartPar
A tensor containing sigma values for each timestep.

\end{description}


\subsection{Returns:}
\label{\detokenize{models:id57}}\begin{description}
\sphinxlineitem{torch.Tensor}
\sphinxAtStartPar
The surrogate target tensor, which is used for model training to
approximate the noise added during diffusion.

\end{description}


\subsection{Example:}
\label{\detokenize{models:id58}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{x\PYGZus{}t} \PYG{o}{=} \PYG{n}{torch}\PYG{o}{.}\PYG{n}{randn}\PYG{p}{(}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{3}\PYG{p}{,} \PYG{l+m+mi}{32}\PYG{p}{,} \PYG{l+m+mi}{32}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{t} \PYG{o}{=} \PYG{l+m+mi}{10}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{alpha} \PYG{o}{=} \PYG{n}{torch}\PYG{o}{.}\PYG{n}{linspace}\PYG{p}{(}\PYG{l+m+mf}{0.1}\PYG{p}{,} \PYG{l+m+mf}{0.9}\PYG{p}{,} \PYG{l+m+mi}{50}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{sigma} \PYG{o}{=} \PYG{n}{torch}\PYG{o}{.}\PYG{n}{linspace}\PYG{p}{(}\PYG{l+m+mf}{0.9}\PYG{p}{,} \PYG{l+m+mf}{0.1}\PYG{p}{,} \PYG{l+m+mi}{50}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{target} \PYG{o}{=} \PYG{n}{surrogate\PYGZus{}target}\PYG{p}{(}\PYG{n}{x\PYGZus{}t}\PYG{p}{,} \PYG{n}{t}\PYG{p}{,} \PYG{n}{alpha}\PYG{p}{,} \PYG{n}{sigma}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{target}\PYG{o}{.}\PYG{n}{shape}\PYG{p}{)}
\end{sphinxVerbatim}

\end{fulllineitems}

\index{variance\_preserving\_diffusion() (in module fireDiff.Models.utils)@\spxentry{variance\_preserving\_diffusion()}\spxextra{in module fireDiff.Models.utils}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{models:fireDiff.Models.utils.variance_preserving_diffusion}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{fireDiff.Models.utils.}}\sphinxbfcode{\sphinxupquote{variance\_preserving\_diffusion}}}{\sphinxparam{\DUrole{n}{x\_0}}\sphinxparamcomma \sphinxparam{\DUrole{n}{t}}\sphinxparamcomma \sphinxparam{\DUrole{n}{alpha\_tau}}\sphinxparamcomma \sphinxparam{\DUrole{n}{sigma\_tau}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Apply variance\sphinxhyphen{}preserving diffusion to an input tensor at a specific
timestep.


\subsection{Parameters:}
\label{\detokenize{models:id59}}\begin{description}
\sphinxlineitem{x\_0}{[}torch.Tensor{]}
\sphinxAtStartPar
The original input tensor, representing the initial data
(e.g., an image).

\sphinxlineitem{t}{[}int{]}
\sphinxAtStartPar
The timestep at which to apply the diffusion process.

\sphinxlineitem{alpha\_tau}{[}torch.Tensor{]}
\sphinxAtStartPar
A tensor containing precomputed alpha values for each timestep.

\sphinxlineitem{sigma\_tau}{[}torch.Tensor{]}
\sphinxAtStartPar
A tensor containing precomputed sigma values for each timestep.

\end{description}


\subsection{Returns:}
\label{\detokenize{models:id60}}\begin{description}
\sphinxlineitem{torch.Tensor}
\sphinxAtStartPar
The diffused tensor \sphinxtitleref{z\_t}, which is the result of applying the
diffusion process to \sphinxtitleref{x\_0} at timestep \sphinxtitleref{t}.

\end{description}


\subsection{Example:}
\label{\detokenize{models:id61}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{x\PYGZus{}0} \PYG{o}{=} \PYG{n}{torch}\PYG{o}{.}\PYG{n}{randn}\PYG{p}{(}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{3}\PYG{p}{,} \PYG{l+m+mi}{32}\PYG{p}{,} \PYG{l+m+mi}{32}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{t} \PYG{o}{=} \PYG{l+m+mi}{10}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{alpha\PYGZus{}tau} \PYG{o}{=} \PYG{n}{torch}\PYG{o}{.}\PYG{n}{linspace}\PYG{p}{(}\PYG{l+m+mf}{0.1}\PYG{p}{,} \PYG{l+m+mf}{0.9}\PYG{p}{,} \PYG{l+m+mi}{50}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{sigma\PYGZus{}tau} \PYG{o}{=} \PYG{n}{torch}\PYG{o}{.}\PYG{n}{linspace}\PYG{p}{(}\PYG{l+m+mf}{0.9}\PYG{p}{,} \PYG{l+m+mf}{0.1}\PYG{p}{,} \PYG{l+m+mi}{50}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{z\PYGZus{}t} \PYG{o}{=} \PYG{n}{variance\PYGZus{}preserving\PYGZus{}diffusion}\PYG{p}{(}\PYG{n}{x\PYGZus{}0}\PYG{p}{,} \PYG{n}{t}\PYG{p}{,} \PYG{n}{alpha\PYGZus{}tau}\PYG{p}{,} \PYG{n}{sigma\PYGZus{}tau}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{z\PYGZus{}t}\PYG{o}{.}\PYG{n}{shape}\PYG{p}{)}
\end{sphinxVerbatim}

\end{fulllineitems}


\sphinxstepscope


\chapter{Datasets}
\label{\detokenize{datasets:datasets}}\label{\detokenize{datasets::doc}}

\section{fireDiff.Datasets.pairdataset}
\label{\detokenize{datasets:module-fireDiff.Datasets.pairdataset}}\label{\detokenize{datasets:firediff-datasets-pairdataset}}\index{module@\spxentry{module}!fireDiff.Datasets.pairdataset@\spxentry{fireDiff.Datasets.pairdataset}}\index{fireDiff.Datasets.pairdataset@\spxentry{fireDiff.Datasets.pairdataset}!module@\spxentry{module}}\index{VideoFramePairsDataset (class in fireDiff.Datasets.pairdataset)@\spxentry{VideoFramePairsDataset}\spxextra{class in fireDiff.Datasets.pairdataset}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{datasets:fireDiff.Datasets.pairdataset.VideoFramePairsDataset}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{class\DUrole{w}{ }}}\sphinxcode{\sphinxupquote{fireDiff.Datasets.pairdataset.}}\sphinxbfcode{\sphinxupquote{VideoFramePairsDataset}}}{\sphinxparam{\DUrole{n}{video\_dir}}\sphinxparamcomma \sphinxparam{\DUrole{n}{transform}\DUrole{o}{=}\DUrole{default_value}{None}}\sphinxparamcomma \sphinxparam{\DUrole{n}{timegap}\DUrole{o}{=}\DUrole{default_value}{1}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Bases: \sphinxcode{\sphinxupquote{Dataset}}

\sphinxAtStartPar
A dataset class for creating pairs of grayscale video frames from a
directory of video files.


\subsection{Attributes:}
\label{\detokenize{datasets:attributes}}\begin{description}
\sphinxlineitem{video\_dir}{[}str{]}
\sphinxAtStartPar
The directory containing the video files.

\sphinxlineitem{transform}{[}callable, optional{]}
\sphinxAtStartPar
A function/transform to apply to the video frames.

\sphinxlineitem{timegap}{[}int, optional{]}
\sphinxAtStartPar
The gap between consecutive frames in a pair, default is 1.

\sphinxlineitem{video\_files}{[}list of str{]}
\sphinxAtStartPar
A list of paths to the video files in the directory.

\sphinxlineitem{frame\_pairs}{[}list of tuples{]}
\sphinxAtStartPar
A list of tuples, where each tuple contains two consecutive frames
with a time gap.

\end{description}

\sphinxAtStartPar
Initializes the VideoFramePairsDataset.


\subsection{Parameters:}
\label{\detokenize{datasets:parameters}}\begin{description}
\sphinxlineitem{video\_dir}{[}str{]}
\sphinxAtStartPar
The directory containing the video files.

\sphinxlineitem{transform}{[}callable, optional{]}
\sphinxAtStartPar
A function/transform to apply to the video frames.

\sphinxlineitem{timegap}{[}int, optional{]}
\sphinxAtStartPar
The gap between consecutive frames in a pair, default is 1.

\end{description}

\end{fulllineitems}



\section{fireDiff.Datasets.videodataset}
\label{\detokenize{datasets:module-fireDiff.Datasets.videodataset}}\label{\detokenize{datasets:firediff-datasets-videodataset}}\index{module@\spxentry{module}!fireDiff.Datasets.videodataset@\spxentry{fireDiff.Datasets.videodataset}}\index{fireDiff.Datasets.videodataset@\spxentry{fireDiff.Datasets.videodataset}!module@\spxentry{module}}\index{VideoDataset (class in fireDiff.Datasets.videodataset)@\spxentry{VideoDataset}\spxextra{class in fireDiff.Datasets.videodataset}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{datasets:fireDiff.Datasets.videodataset.VideoDataset}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{class\DUrole{w}{ }}}\sphinxcode{\sphinxupquote{fireDiff.Datasets.videodataset.}}\sphinxbfcode{\sphinxupquote{VideoDataset}}}{\sphinxparam{\DUrole{n}{video\_folder}}\sphinxparamcomma \sphinxparam{\DUrole{n}{num\_videos}}\sphinxparamcomma \sphinxparam{\DUrole{n}{num\_frames\_per\_video}}\sphinxparamcomma \sphinxparam{\DUrole{n}{frame\_size}}\sphinxparamcomma \sphinxparam{\DUrole{n}{transform}\DUrole{o}{=}\DUrole{default_value}{None}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Bases: \sphinxcode{\sphinxupquote{Dataset}}

\sphinxAtStartPar
A PyTorch Dataset class for loading frames from multiple videos stored in
a folder. The frames are converted to grayscale and can be optionally
transformed.


\subsection{Parameters:}
\label{\detokenize{datasets:id1}}\begin{description}
\sphinxlineitem{video\_folder}{[}str{]}
\sphinxAtStartPar
The directory containing the video files.

\sphinxlineitem{num\_videos}{[}int{]}
\sphinxAtStartPar
The number of videos to load from the folder.

\sphinxlineitem{num\_frames\_per\_video}{[}int{]}
\sphinxAtStartPar
The number of frames to load from each video.

\sphinxlineitem{frame\_size}{[}tuple{]}
\sphinxAtStartPar
The desired frame size (height, width) for the loaded frames.

\sphinxlineitem{transform}{[}callable, optional, default=None{]}
\sphinxAtStartPar
A function/transform that takes in a frame and returns a transformed
version.

\end{description}


\subsection{Returns:}
\label{\detokenize{datasets:returns}}
\sphinxAtStartPar
None
\index{load\_video() (fireDiff.Datasets.videodataset.VideoDataset method)@\spxentry{load\_video()}\spxextra{fireDiff.Datasets.videodataset.VideoDataset method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{datasets:fireDiff.Datasets.videodataset.VideoDataset.load_video}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{load\_video}}}{\sphinxparam{\DUrole{n}{video\_path}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Loads a single video from the specified path, converts its frames to
grayscale, and resizes them to the specified frame size.


\subsubsection{Parameters:}
\label{\detokenize{datasets:id2}}\begin{description}
\sphinxlineitem{video\_path}{[}str{]}
\sphinxAtStartPar
The path to the video file to be loaded.

\end{description}


\subsubsection{Returns:}
\label{\detokenize{datasets:id3}}\begin{description}
\sphinxlineitem{np.ndarray}
\sphinxAtStartPar
An array of grayscale frames from the video.

\end{description}

\end{fulllineitems}

\index{load\_videos() (fireDiff.Datasets.videodataset.VideoDataset method)@\spxentry{load\_videos()}\spxextra{fireDiff.Datasets.videodataset.VideoDataset method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{datasets:fireDiff.Datasets.videodataset.VideoDataset.load_videos}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{load\_videos}}}{}{}
\pysigstopsignatures
\sphinxAtStartPar
Loads frames from multiple videos in the specified folder. Each video
is loaded, converted to grayscale, resized, and a specified number of
frames are selected.


\subsubsection{Returns:}
\label{\detokenize{datasets:id4}}\begin{description}
\sphinxlineitem{list}
\sphinxAtStartPar
A list containing all the loaded and processed frames from all
videos.

\end{description}

\end{fulllineitems}


\end{fulllineitems}


\sphinxstepscope


\chapter{Utilities}
\label{\detokenize{utils:utilities}}\label{\detokenize{utils::doc}}

\section{fireDiff.Utils.utilities}
\label{\detokenize{utils:module-fireDiff.Utils.utilities}}\label{\detokenize{utils:firediff-utils-utilities}}\index{module@\spxentry{module}!fireDiff.Utils.utilities@\spxentry{fireDiff.Utils.utilities}}\index{fireDiff.Utils.utilities@\spxentry{fireDiff.Utils.utilities}!module@\spxentry{module}}\index{calculate\_matching\_percentage() (in module fireDiff.Utils.utilities)@\spxentry{calculate\_matching\_percentage()}\spxextra{in module fireDiff.Utils.utilities}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{utils:fireDiff.Utils.utilities.calculate_matching_percentage}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{fireDiff.Utils.utilities.}}\sphinxbfcode{\sphinxupquote{calculate\_matching\_percentage}}}{\sphinxparam{\DUrole{n}{tensor1}}\sphinxparamcomma \sphinxparam{\DUrole{n}{tensor2}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Calculate the percentage of elements that have the same value between two
tensors.


\subsection{Parameters:}
\label{\detokenize{utils:parameters}}\begin{description}
\sphinxlineitem{tensor1}{[}torch.Tensor{]}
\sphinxAtStartPar
The first input tensor. This tensor can have any shape, but it must
match the shape of \sphinxtitleref{tensor2}.

\sphinxlineitem{tensor2}{[}torch.Tensor{]}
\sphinxAtStartPar
The second input tensor, which must have the same shape as \sphinxtitleref{tensor1}.

\end{description}


\subsection{Returns:}
\label{\detokenize{utils:returns}}\begin{description}
\sphinxlineitem{float}
\sphinxAtStartPar
The percentage of elements that match between the two tensors. This is
calculated as the number of matching elements divided by the total
number of elements, multiplied by 100.

\end{description}


\subsection{Raises:}
\label{\detokenize{utils:raises}}\begin{description}
\sphinxlineitem{ValueError}
\sphinxAtStartPar
If the input tensors do not have the same shape.

\end{description}


\subsection{Example:}
\label{\detokenize{utils:example}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{torch}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{tensor1} \PYG{o}{=} \PYG{n}{torch}\PYG{o}{.}\PYG{n}{tensor}\PYG{p}{(}\PYG{p}{[}\PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{2}\PYG{p}{,} \PYG{l+m+mi}{3}\PYG{p}{]}\PYG{p}{,} \PYG{p}{[}\PYG{l+m+mi}{4}\PYG{p}{,} \PYG{l+m+mi}{5}\PYG{p}{,} \PYG{l+m+mi}{6}\PYG{p}{]}\PYG{p}{]}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{tensor2} \PYG{o}{=} \PYG{n}{torch}\PYG{o}{.}\PYG{n}{tensor}\PYG{p}{(}\PYG{p}{[}\PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{2}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{,} \PYG{p}{[}\PYG{l+m+mi}{4}\PYG{p}{,} \PYG{l+m+mi}{5}\PYG{p}{,} \PYG{l+m+mi}{6}\PYG{p}{]}\PYG{p}{]}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{percentage} \PYG{o}{=} \PYG{n}{calculate\PYGZus{}matching\PYGZus{}percentage}\PYG{p}{(}\PYG{n}{tensor1}\PYG{p}{,} \PYG{n}{tensor2}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+sa}{f}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Percentage of matching elements: }\PYG{l+s+si}{\PYGZob{}}\PYG{n}{percentage}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{\PYGZpc{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+go}{Percentage of matching elements: 83.33333333333334\PYGZpc{}}
\end{sphinxVerbatim}

\end{fulllineitems}

\index{threshold() (in module fireDiff.Utils.utilities)@\spxentry{threshold()}\spxextra{in module fireDiff.Utils.utilities}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{utils:fireDiff.Utils.utilities.threshold}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{fireDiff.Utils.utilities.}}\sphinxbfcode{\sphinxupquote{threshold}}}{\sphinxparam{\DUrole{n}{image}}\sphinxparamcomma \sphinxparam{\DUrole{n}{value}\DUrole{o}{=}\DUrole{default_value}{0}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Apply a threshold to an image tensor, converting all pixel values to
either 1 or \sphinxhyphen{}1 based on the threshold value.


\subsection{Parameters:}
\label{\detokenize{utils:id1}}\begin{description}
\sphinxlineitem{image}{[}torch.Tensor{]}
\sphinxAtStartPar
The input image as a PyTorch tensor. This tensor can have any shape,
but typically it will be a 2D or 3D tensor representing an image.

\sphinxlineitem{value}{[}int or float, optional{]}
\sphinxAtStartPar
The threshold value to apply. Any pixel value in the input image
greater than or equal to this value will be set to 1, and any pixel
value below this value will be set to \sphinxhyphen{}1.
The default threshold value is 0.

\end{description}


\subsection{Returns:}
\label{\detokenize{utils:id2}}\begin{description}
\sphinxlineitem{torch.Tensor}
\sphinxAtStartPar
A tensor with the same shape as the input image, where each pixel is
either 1 or \sphinxhyphen{}1 depending on the thresholding.

\end{description}


\subsection{Example:}
\label{\detokenize{utils:id3}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{torch}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{image} \PYG{o}{=} \PYG{n}{torch}\PYG{o}{.}\PYG{n}{tensor}\PYG{p}{(}\PYG{p}{[}\PYG{p}{[}\PYG{l+m+mf}{0.5}\PYG{p}{,} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.2}\PYG{p}{]}\PYG{p}{,} \PYG{p}{[}\PYG{l+m+mf}{1.2}\PYG{p}{,} \PYG{l+m+mf}{0.0}\PYG{p}{]}\PYG{p}{]}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{thresholded\PYGZus{}image} \PYG{o}{=} \PYG{n}{threshold}\PYG{p}{(}\PYG{n}{image}\PYG{p}{,} \PYG{n}{value}\PYG{o}{=}\PYG{l+m+mf}{0.1}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{thresholded\PYGZus{}image}\PYG{p}{)}
\PYG{g+go}{(tensor([[ 1, \PYGZhy{}1],}
\PYG{g+go}{         [ 1, \PYGZhy{}1]]),)}
\end{sphinxVerbatim}

\end{fulllineitems}



\bigskip\hrule\bigskip

\begin{itemize}
\item {} 
\sphinxAtStartPar
\DUrole{xref,std,std-ref}{genindex}

\item {} 
\sphinxAtStartPar
\DUrole{xref,std,std-ref}{modindex}

\item {} 
\sphinxAtStartPar
\DUrole{xref,std,std-ref}{search}

\end{itemize}


\renewcommand{\indexname}{Python Module Index}
\begin{sphinxtheindex}
\let\bigletter\sphinxstyleindexlettergroup
\bigletter{f}
\item\relax\sphinxstyleindexentry{fireDiff.Datasets.pairdataset}\sphinxstyleindexpageref{datasets:\detokenize{module-fireDiff.Datasets.pairdataset}}
\item\relax\sphinxstyleindexentry{fireDiff.Datasets.videodataset}\sphinxstyleindexpageref{datasets:\detokenize{module-fireDiff.Datasets.videodataset}}
\item\relax\sphinxstyleindexentry{fireDiff.Models.cae}\sphinxstyleindexpageref{models:\detokenize{module-fireDiff.Models.cae}}
\item\relax\sphinxstyleindexentry{fireDiff.Models.deterministicmodel}\sphinxstyleindexpageref{models:\detokenize{module-fireDiff.Models.deterministicmodel}}
\item\relax\sphinxstyleindexentry{fireDiff.Models.diffusionmodel}\sphinxstyleindexpageref{models:\detokenize{module-fireDiff.Models.diffusionmodel}}
\item\relax\sphinxstyleindexentry{fireDiff.Models.fcae}\sphinxstyleindexpageref{models:\detokenize{module-fireDiff.Models.fcae}}
\item\relax\sphinxstyleindexentry{fireDiff.Models.unet}\sphinxstyleindexpageref{models:\detokenize{module-fireDiff.Models.unet}}
\item\relax\sphinxstyleindexentry{fireDiff.Models.unet\_predictor}\sphinxstyleindexpageref{models:\detokenize{module-fireDiff.Models.unet_predictor}}
\item\relax\sphinxstyleindexentry{fireDiff.Models.utils}\sphinxstyleindexpageref{models:\detokenize{module-fireDiff.Models.utils}}
\item\relax\sphinxstyleindexentry{fireDiff.Utils.utilities}\sphinxstyleindexpageref{utils:\detokenize{module-fireDiff.Utils.utilities}}
\end{sphinxtheindex}

\renewcommand{\indexname}{Index}
\printindex
\end{document}